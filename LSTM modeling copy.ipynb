{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84781371",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f5ac23",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ef6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# !{sys.executable} -m pip install tensorflow-macos\n",
    "# !{sys.executable} -m pip install tensorflow-metal\n",
    "# !{sys.executable} -m pip install keras\n",
    "\n",
    "# # if using M1 chip in apple, make sure to update anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e0ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import array\n",
    "import datetime as dt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adccab3b",
   "metadata": {},
   "source": [
    "### About LSTM\n",
    "\n",
    "[Tutorial](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63433e8",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "* 01/01/2018 - 07/01/2023\n",
    "* Train: 2018-2021\n",
    "* Test: 2022-July 2023 (tech recession!)\n",
    "* Companies: Amazon, Apple, Google, Microsoft, Nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2aa2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to get this file, first run the notebook: Retrieve entire stock price data.ipynb\n",
    "# stocks = pd.read_csv('quandl_data_table_downloads/QUOTEMEDIA/PRICES_20230712.zip')\n",
    "\n",
    "# company_tickers = ['AMZN', 'AAPL', 'GOOG', 'MSFT', 'NVDA']\n",
    "# start_date = pd.to_datetime('2017-12-01')\n",
    "# end_date = pd.to_datetime('2023-07-01')\n",
    "\n",
    "# stocks = stocks.loc[stocks['ticker'].isin(company_tickers)]\n",
    "# stocks = stocks[['date', 'ticker', 'adj_close']]\n",
    "# stocks['date'] = pd.to_datetime(stocks['date'])\n",
    "# stocks = stocks.loc[(stocks['date'] >= pd.to_datetime(start_date))\n",
    "#                       & (stocks['date'] <= pd.to_datetime(end_date))]\n",
    "# stocks = stocks.sort_values('date')\n",
    "\n",
    "# stocks.to_csv('stocks_filtered.csv', index=False)\n",
    "\n",
    "# # # this will be needed later to merge with sentiment analysis dataset\n",
    "# # stocks = stocks.set_index('date').tz_localize('utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd432166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks.shape # there are missing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d5333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - (7015/(365*5))  / 5.5 # percent of missing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb019755",
   "metadata": {},
   "source": [
    "### Directly read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff693b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.read_csv('stocks_filtered.csv')\n",
    "stocks['date'] = pd.to_datetime(stocks['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8c2d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>50.508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>57.977862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>40.542754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>48.957940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>79.231484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker  adj_close\n",
       "0 2017-12-01   GOOG  50.508500\n",
       "1 2017-12-01   AMZN  57.977862\n",
       "2 2017-12-01   AAPL  40.542754\n",
       "3 2017-12-01   NVDA  48.957940\n",
       "4 2017-12-01   MSFT  79.231484"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ab6d7f",
   "metadata": {},
   "source": [
    "### Baseline LSTM\n",
    "\n",
    "No sentiment analysis; only one company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fe8e123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>adj_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>48.957940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>46.228698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>46.496174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>46.872621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>47.548740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ticker  adj_close\n",
       "date                        \n",
       "2017-12-01   NVDA  48.957940\n",
       "2017-12-04   NVDA  46.228698\n",
       "2017-12-05   NVDA  46.496174\n",
       "2017-12-06   NVDA  46.872621\n",
       "2017-12-07   NVDA  47.548740"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nstocks = stocks.loc[stocks['ticker'] == \"NVDA\"]\n",
    "nstocks = nstocks.sort_values('date').set_index('date')\n",
    "nstocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad251f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, n_steps, count_imputations=False,\n",
    "               start_date='2018-01-01', end_date='2023-07-01'):\n",
    "    \"\"\"\n",
    "    reformats stock price data to be a sequence of prices from n_steps days ago\n",
    "    fills in missing values with the most recent available price data\n",
    "    \n",
    "    has an option to count the number of imputations\n",
    "    \n",
    "    returns three arrays:\n",
    "    1. y, \n",
    "    2. X, each element has length n_steps \n",
    "    3. imputations as arrays, where X has n_steps number of columns of \n",
    "    previous n_steps stock prices\n",
    "    \n",
    "    df: DataFrame with 'date' and 'adj_close' price columns\n",
    "    n_steps: look back window. < 30\n",
    "    \n",
    "    left and right inclusive\n",
    "    \"\"\"\n",
    "    \n",
    "    start_dt = pd.to_datetime(start_date)\n",
    "    end_dt = pd.to_datetime(end_date)\n",
    "    \n",
    "    all_dates = pd.date_range(start = start_dt, end = end_dt)\n",
    "    missing_dates = all_dates.difference(df.index)\n",
    "    y_dates = df.index[(df.index >= start_dt) &\n",
    "                       (df.index <= end_dt)]\n",
    "    \n",
    "    delta = pd.Timedelta(str(n_steps) + \" days\")\n",
    "    \n",
    "    y = []\n",
    "    X = []\n",
    "    imputations = []\n",
    "\n",
    "    for y_date in y_dates:\n",
    "\n",
    "        y.append(df.adj_close.loc[y_date])\n",
    "\n",
    "        # dates with price data\n",
    "        X_dates = nstocks.index[(df.index >= y_date - delta) & \n",
    "                                (df.index < y_date)]\n",
    "\n",
    "        all_X_dates = pd.date_range(start = y_date - delta, \n",
    "                                    end = y_date,\n",
    "                                    inclusive = \"left\") # exclude y_date\n",
    "\n",
    "        missing = all_X_dates.difference(X_dates)\n",
    "\n",
    "        X_prices = []\n",
    "        count_imputations = 0\n",
    "\n",
    "        for date in all_X_dates:\n",
    "\n",
    "            if date in missing:\n",
    "\n",
    "                # most recent date with price data\n",
    "                impute_date = max(df.index[df.index < date])\n",
    "                X_prices.append(df['adj_close'].loc[impute_date])\n",
    "\n",
    "                count_imputations += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                X_prices.append(df['adj_close'].loc[date])\n",
    "\n",
    "        X.append(X_prices)\n",
    "        imputations.append(count_imputations)\n",
    "        \n",
    "    if count_imputations:\n",
    "        return array(X), array(y), array(imputations)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae887c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, imputations = split_data(nstocks, 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5f11759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({\"imputations\": imputations}).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4b2f7",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b434c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split_data(nstocks, 5, start_date='2018-01-01', end_date='2021-12-31')\n",
    "X_train, y_train = train[0], train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c20e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = split_data(nstocks, 5, start_date='2022-01-01', end_date='2023-07-01')\n",
    "X_test, y_test = test[0], test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39d4e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 13:58:43.818483: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-07-15 13:58:43.818504: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-07-15 13:58:43.818507: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-07-15 13:58:43.819050: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-15 13:58:43.819258: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 5\n",
    "n_features = 1 # univariate time series\n",
    "\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# switching relu activiation to tanh\n",
    "\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3b9924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 5, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fee307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3becb0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(X_train, y_train, epochs=20, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
