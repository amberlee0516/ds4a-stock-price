{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8298734",
   "metadata": {},
   "source": [
    "# Retrieving headlines\n",
    "\n",
    "### Set up\n",
    "\n",
    "You may need to install the libraries `beautifulsoup4` and `newspaper3k`.\n",
    "\n",
    "The `GNews` library needs to be installed  from the Github source. Here is a [StackOverflow forum] I referenced, in case it is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2b5ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.9/site-packages (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4) (2.3.1)\r\n",
      "Collecting newspaper3k\r\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m211.1/211.1 kB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (4.11.1)\r\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (9.4.0)\r\n",
      "Requirement already satisfied: PyYAML>=3.11 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (6.0)\r\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (1.1.0)\r\n",
      "Requirement already satisfied: lxml>=3.6.0 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (4.9.1)\r\n",
      "Requirement already satisfied: nltk>=3.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (3.7)\r\n",
      "Requirement already satisfied: requests>=2.10.0 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (2.28.1)\r\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\r\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m81.1/81.1 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: tldextract>=2.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (3.2.0)\r\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\r\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting jieba3k>=0.35.1 (from newspaper3k)\r\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.4/7.4 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.9/site-packages (from newspaper3k) (2.8.2)\r\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\r\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.1)\r\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.9/site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\r\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\r\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (1.1.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (2022.7.9)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k) (4.64.1)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (3.3)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (1.26.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests>=2.10.0->newspaper3k) (2022.9.24)\r\n",
      "Requirement already satisfied: requests-file>=1.4 in /opt/anaconda3/lib/python3.9/site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\r\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/anaconda3/lib/python3.9/site-packages (from tldextract>=2.0.1->newspaper3k) (3.6.0)\r\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\r\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13541 sha256=c0edc9ad0364606115b836e13f899baa201d1ab82a8fcf995bbad4c67631f720\r\n",
      "  Stored in directory: /Users/cindy/Library/Caches/pip/wheels/94/ad/df/a2a01300cea47d5695f242f7e925a805970106fd9e4b151468\r\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=cf03bf4817bc84e648544148198e2ef4dc7a066d6021fb7db3451df0e4ba431b\r\n",
      "  Stored in directory: /Users/cindy/Library/Caches/pip/wheels/43/4a/c2/61a371b2524ac90805391c660d8dc4505705297f25e2b85a5d\r\n",
      "  Building wheel for jieba3k (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=36692c41d7199eebf6c708d9c75195236769cd38fdd6a47bae402f916f07b213\r\n",
      "  Stored in directory: /Users/cindy/Library/Caches/pip/wheels/c2/22/59/8214a8d6357e9f540ce1f37f9a4362b6156b4ca81b37f1945f\r\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=20e165eb18b63f1f8ac946911ee1ebf85e6484ecdb333ec81c29c388c48c1d2c\r\n",
      "  Stored in directory: /Users/cindy/Library/Caches/pip/wheels/65/7a/a7/78c287f64e401255dff4c13fdbc672fed5efbfd21c530114e1\r\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\r\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, feedfinder2, newspaper3k\r\n",
      "Successfully installed feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 sgmllib3k-1.0.0 tinysegmenter-0.3\r\n",
      "Collecting git+https://github.com/ranahaani/GNews.git\r\n",
      "  Cloning https://github.com/ranahaani/GNews.git to /private/var/folders/97/ry8p7x356bbbk7qdw9k14pyr0000gn/T/pip-req-build-l10ne1ck\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ranahaani/GNews.git /private/var/folders/97/ry8p7x356bbbk7qdw9k14pyr0000gn/T/pip-req-build-l10ne1ck\r\n",
      "  Resolved https://github.com/ranahaani/GNews.git to commit 8591313e3fdaaf44e2e09f2265254fc3aaea8b56\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: feedparser~=6.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from gnews==0.2.7) (6.0.10)\r\n",
      "Collecting bs4~=0.0.1 (from gnews==0.2.7)\r\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting beautifulsoup4~=4.9.3 (from gnews==0.2.7)\r\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m115.8/115.8 kB\u001B[0m \u001B[31m1.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting pymongo~=3.12.0 (from gnews==0.2.7)\r\n",
      "  Downloading pymongo-3.12.3-cp39-cp39-macosx_10_9_x86_64.whl (395 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m395.4/395.4 kB\u001B[0m \u001B[31m2.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting dnspython~=1.16.0 (from gnews==0.2.7)\r\n",
      "  Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m188.4/188.4 kB\u001B[0m \u001B[31m603.4 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting python-dotenv~=0.19.0 (from gnews==0.2.7)\r\n",
      "  Downloading python_dotenv-0.19.2-py2.py3-none-any.whl (17 kB)\r\n",
      "Collecting requests==2.26.0 (from gnews==0.2.7)\r\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.3/62.3 kB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->gnews==0.2.7) (1.26.11)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->gnews==0.2.7) (2022.9.24)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->gnews==0.2.7) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests==2.26.0->gnews==0.2.7) (3.3)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4~=4.9.3->gnews==0.2.7) (2.3.1)\r\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/lib/python3.9/site-packages (from feedparser~=6.0.2->gnews==0.2.7) (1.0.0)\r\n",
      "Building wheels for collected packages: gnews, bs4\r\n",
      "  Building wheel for gnews (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for gnews: filename=gnews-0.2.7-py3-none-any.whl size=16161 sha256=c96a5b0cc03d40a49b997e2361ce877b195278d5b611c5958355f2cbd8c5ae9e\r\n",
      "  Stored in directory: /private/var/folders/97/ry8p7x356bbbk7qdw9k14pyr0000gn/T/pip-ephem-wheel-cache-sfptsfot/wheels/17/57/85/1c4d5a4488fc09b600274e90a6a5ea4f8f63d672688a9ac885\r\n",
      "  Building wheel for bs4 (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=61f568861651c23b3556c58ace7344dd3e23f08f644c1d017511af9423833ff4\r\n",
      "  Stored in directory: /Users/cindy/Library/Caches/pip/wheels/73/2b/cb/099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\r\n",
      "Successfully built gnews bs4\r\n",
      "Installing collected packages: requests, python-dotenv, pymongo, dnspython, beautifulsoup4, bs4, gnews\r\n",
      "  Attempting uninstall: requests\r\n",
      "    Found existing installation: requests 2.28.1\r\n",
      "    Uninstalling requests-2.28.1:\r\n",
      "      Successfully uninstalled requests-2.28.1\r\n",
      "  Attempting uninstall: python-dotenv\r\n",
      "    Found existing installation: python-dotenv 1.0.0\r\n",
      "    Uninstalling python-dotenv-1.0.0:\r\n",
      "      Successfully uninstalled python-dotenv-1.0.0\r\n",
      "  Attempting uninstall: beautifulsoup4\r\n",
      "    Found existing installation: beautifulsoup4 4.11.1\r\n",
      "    Uninstalling beautifulsoup4-4.11.1:\r\n",
      "      Successfully uninstalled beautifulsoup4-4.11.1\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "spyder 5.3.3 requires pyqt5<5.16, which is not installed.\r\n",
      "spyder 5.3.3 requires pyqtwebengine<5.16, which is not installed.\r\n",
      "conda-repo-cli 1.0.20 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\r\n",
      "conda-repo-cli 1.0.20 requires nbformat==5.4.0, but you have nbformat 5.5.0 which is incompatible.\r\n",
      "conda-repo-cli 1.0.20 requires requests==2.28.1, but you have requests 2.26.0 which is incompatible.\r\n",
      "panel 0.13.1 requires bokeh<2.5.0,>=2.4.0, but you have bokeh 2.0.1 which is incompatible.\r\n",
      "yfinance 0.2.12 requires beautifulsoup4>=4.11.1, but you have beautifulsoup4 4.9.3 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed beautifulsoup4-4.9.3 bs4-0.0.1 dnspython-1.16.0 gnews-0.2.7 pymongo-3.12.3 python-dotenv-0.19.2 requests-2.26.0\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install newspaper3k\n",
    "!{sys.executable} -m pip install git+https://github.com/ranahaani/GNews.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cd78bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gnews'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgnews\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GNews\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mdt\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'gnews'"
     ]
    }
   ],
   "source": [
    "from gnews import GNews\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1868ae19",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87418aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the 2 week periods\n",
    "\n",
    "first_day = np.ones(12, dtype = int)\n",
    "middle_day = np.repeat(15, 12)\n",
    "middle_day[1] = 14 # feb\n",
    "last_day = np.tile([31, 30], 6)\n",
    "last_day[7:12] = last_day[0:5]\n",
    "last_day[1] = 28 # feb\n",
    "\n",
    "start_days = []\n",
    "end_days = []\n",
    "\n",
    "for i in range(12):\n",
    "    \n",
    "    start_days.append(first_day[i])\n",
    "    end_days.append(middle_day[i])\n",
    "    \n",
    "    start_days.append(middle_day[i])\n",
    "    end_days.append(last_day[i])\n",
    "\n",
    "months = np.repeat(range(12), 2) + 1\n",
    "\n",
    "# print(start_days)\n",
    "# print(end_days)\n",
    "# print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4535b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headlines(year, keyword):\n",
    "    \"\"\"\n",
    "    year: int \n",
    "    keyword: str, the company name\n",
    "    \"\"\"\n",
    "    \n",
    "    headlines_df = pd.DataFrame(columns = [\"date\", \"title\", \"publisher\"])\n",
    "    \n",
    "    for two_week_period in range(24):\n",
    "    \n",
    "        month = months[two_week_period]\n",
    "        start_day = start_days[two_week_period]\n",
    "        end_day = end_days[two_week_period]\n",
    "\n",
    "        start = dt.datetime(year, month, start_day)\n",
    "        end = dt.datetime(year, month, end_day)\n",
    "\n",
    "        gnews = GNews(language = \"en\",\n",
    "                      start_date = start, \n",
    "                      end_date = end)\n",
    "\n",
    "        news_df = pd.DataFrame(gnews.get_news(keyword))\n",
    "\n",
    "        if news_df.shape == (0, 0):\n",
    "            print(f\"No news between {start} and {end} for {keyword}.\\n\")\n",
    "            continue\n",
    "\n",
    "        news_df['date'] = pd.to_datetime(news_df['published date'])\n",
    "\n",
    "        headlines_df = pd.concat([headlines_df, news_df[['date', 'title', 'publisher']].copy()],\n",
    "                                 ignore_index = True)\n",
    "    \n",
    "    return headlines_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042c345",
   "metadata": {},
   "source": [
    "### Retrieve data\n",
    "\n",
    "Only run one cell at a time!\n",
    "\n",
    "When running these cells, you will get errors about having no news for certain time periods. That's fine, don't re-run the cell. Keep it the way it is so we have records about when the headlines were missing. Just commit and push what you have from that one run.\n",
    "\n",
    "One day later, it can be helpful to duplicate the cell, change the `range(2018, 2023+1)` to start from whichever year there is missing headlines, and run the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wafer: apple, amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591206eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apple\n",
    "\n",
    "company = \"Apple\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3559c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amazon\n",
    "\n",
    "company = \"Amazon\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cindy: nvidia, microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4770bcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No news between 2023-07-15 00:00:00 and 2023-07-31 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-08-01 00:00:00 and 2023-08-15 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-08-15 00:00:00 and 2023-08-31 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-09-01 00:00:00 and 2023-09-15 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-09-15 00:00:00 and 2023-09-30 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-10-01 00:00:00 and 2023-10-15 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-10-15 00:00:00 and 2023-10-31 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-11-01 00:00:00 and 2023-11-15 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-11-15 00:00:00 and 2023-11-30 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-12-01 00:00:00 and 2023-12-15 00:00:00 for Google.\n",
      "\n",
      "No news between 2023-12-15 00:00:00 and 2023-12-31 00:00:00 for Google.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# nvidia\n",
    "\n",
    "company = \"Google\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c690786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No news between 2023-07-15 00:00:00 and 2023-07-31 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-08-01 00:00:00 and 2023-08-15 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-08-15 00:00:00 and 2023-08-31 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-09-01 00:00:00 and 2023-09-15 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-09-15 00:00:00 and 2023-09-30 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-10-01 00:00:00 and 2023-10-15 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-10-15 00:00:00 and 2023-10-31 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-11-01 00:00:00 and 2023-11-15 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-11-15 00:00:00 and 2023-11-30 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-12-01 00:00:00 and 2023-12-15 00:00:00 for Microsoft.\n",
      "\n",
      "No news between 2023-12-15 00:00:00 and 2023-12-31 00:00:00 for Microsoft.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# microsoft\n",
    "\n",
    "company = \"Microsoft\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63d02f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "AAPL = pd.DataFrame()\n",
    "MSFT = pd.DataFrame()\n",
    "AMZN = pd.DataFrame()\n",
    "GOOG = pd.DataFrame()\n",
    "NVDA = pd.DataFrame()\n",
    "for year in range(2018, 2023+1):\n",
    "    AMZN = AMZN.append([pd.read_csv('headlines/' + str(year) + '_Amazon_headlines.csv')],\n",
    "              ignore_index = True)\n",
    "    AAPL = AAPL.append([pd.read_csv('headlines/' + str(year) + '_Apple_headlines.csv')],\n",
    "              ignore_index = True)\n",
    "    GOOG = GOOG.append([pd.read_csv('headlines/' + str(year) + '_Google_headlines.csv')],\n",
    "              ignore_index = True)\n",
    "    MSFT = MSFT.append([pd.read_csv('headlines/' + str(year) + '_Microsoft_headlines.csv')],\n",
    "              ignore_index = True)\n",
    "    NVDA = NVDA.append([pd.read_csv('headlines/' + str(year) + '_Nvidia_headlines.csv')],\n",
    "              ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7cdac5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.insert(1,'ticker', 'AMZN')\n",
    "AAPL.insert(1, 'ticker', 'AAPL')\n",
    "GOOG.insert(1, 'ticker', 'GOOG')\n",
    "MSFT.insert(1, 'ticker', 'MSFT')\n",
    "NVDA.insert(1, 'ticker', 'NVDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7079c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = pd.concat([AMZN, AAPL, GOOG, MSFT, NVDA], ignore_index = True)\n",
    "headlines['date'] = pd.to_datetime(headlines['date']).dt.tz_convert(None)\n",
    "headlines.sort_values(by = ['date','ticker'], ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fd4fdc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3 tips to maximize Apple's free Pages word pro...</td>\n",
       "      <td>TechRepublic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>The 20 best iOS games of 2017 - Macworld</td>\n",
       "      <td>Macworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>How to Switch Apple Watch Home Screen from Gri...</td>\n",
       "      <td>Wccftech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Will Ferrell, Molly Shannon Tease Trump and Ti...</td>\n",
       "      <td>Hollywood Reporter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>The Limits of Amazon - WSJ - The Wall Street J...</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65704</th>\n",
       "      <td>2023-07-11 19:49:00</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Google's Searchbot Could Put Me Out of a Job -...</td>\n",
       "      <td>The Atlantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65705</th>\n",
       "      <td>2023-07-11 20:08:55</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Google On Fixing Discovered Currently Not Inde...</td>\n",
       "      <td>Search Engine Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65706</th>\n",
       "      <td>2023-07-11 20:16:08</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Google’s head of AR software quits, citing “un...</td>\n",
       "      <td>Ars Technica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65707</th>\n",
       "      <td>2023-07-11 23:30:19</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Google quietly ditched plans for an AI-powered...</td>\n",
       "      <td>CNBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65708</th>\n",
       "      <td>2023-07-12 01:09:00</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>Google hit with class-action lawsuit over AI d...</td>\n",
       "      <td>Reuters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65709 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date ticker  \\\n",
       "0     2018-01-01 08:00:00   AAPL   \n",
       "1     2018-01-01 08:00:00   AAPL   \n",
       "2     2018-01-01 08:00:00   AAPL   \n",
       "3     2018-01-01 08:00:00   AMZN   \n",
       "4     2018-01-01 08:00:00   AMZN   \n",
       "...                   ...    ...   \n",
       "65704 2023-07-11 19:49:00   GOOG   \n",
       "65705 2023-07-11 20:08:55   GOOG   \n",
       "65706 2023-07-11 20:16:08   GOOG   \n",
       "65707 2023-07-11 23:30:19   GOOG   \n",
       "65708 2023-07-12 01:09:00   GOOG   \n",
       "\n",
       "                                                   title  \\\n",
       "0      3 tips to maximize Apple's free Pages word pro...   \n",
       "1               The 20 best iOS games of 2017 - Macworld   \n",
       "2      How to Switch Apple Watch Home Screen from Gri...   \n",
       "3      Will Ferrell, Molly Shannon Tease Trump and Ti...   \n",
       "4      The Limits of Amazon - WSJ - The Wall Street J...   \n",
       "...                                                  ...   \n",
       "65704  Google's Searchbot Could Put Me Out of a Job -...   \n",
       "65705  Google On Fixing Discovered Currently Not Inde...   \n",
       "65706  Google’s head of AR software quits, citing “un...   \n",
       "65707  Google quietly ditched plans for an AI-powered...   \n",
       "65708  Google hit with class-action lawsuit over AI d...   \n",
       "\n",
       "                     publisher  \n",
       "0                 TechRepublic  \n",
       "1                     Macworld  \n",
       "2                     Wccftech  \n",
       "3           Hollywood Reporter  \n",
       "4      The Wall Street Journal  \n",
       "...                        ...  \n",
       "65704             The Atlantic  \n",
       "65705    Search Engine Journal  \n",
       "65706             Ars Technica  \n",
       "65707                     CNBC  \n",
       "65708                  Reuters  \n",
       "\n",
       "[65709 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines['publisher'] = headlines['publisher'].apply(lambda x: ' '.join(x.split()[3:]).strip(\"'\").strip(\"}\")[:-1])\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b8f8d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines.to_csv('headlines.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df37443",
   "metadata": {},
   "source": [
    "# Add sentiment analysis to headlines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7609e310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/amberlee/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1b3b268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3 tips to maximize Apple's free Pages word pro...</td>\n",
       "      <td>TechRepublic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>The 20 best iOS games of 2017 - Macworld</td>\n",
       "      <td>Macworld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>How to Switch Apple Watch Home Screen from Gri...</td>\n",
       "      <td>Wccftech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Will Ferrell, Molly Shannon Tease Trump and Ti...</td>\n",
       "      <td>Hollywood Reporter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 08:00:00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>The Limits of Amazon - WSJ - The Wall Street J...</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date ticker  \\\n",
       "0  2018-01-01 08:00:00   AAPL   \n",
       "1  2018-01-01 08:00:00   AAPL   \n",
       "2  2018-01-01 08:00:00   AAPL   \n",
       "3  2018-01-01 08:00:00   AMZN   \n",
       "4  2018-01-01 08:00:00   AMZN   \n",
       "\n",
       "                                               title                publisher  \n",
       "0  3 tips to maximize Apple's free Pages word pro...             TechRepublic  \n",
       "1           The 20 best iOS games of 2017 - Macworld                 Macworld  \n",
       "2  How to Switch Apple Watch Home Screen from Gri...                 Wccftech  \n",
       "3  Will Ferrell, Molly Shannon Tease Trump and Ti...       Hollywood Reporter  \n",
       "4  The Limits of Amazon - WSJ - The Wall Street J...  The Wall Street Journal  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_csv('headlines.csv')\n",
    "headlines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a2907",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3185d738",
   "metadata": {},
   "source": [
    "**Remove publisher tag -- this a rough solution that works for most tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a40d5ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Limits of Amazon', 'WSJ', 'The Wall Street Journal']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines['title'][4].split(' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d0e6fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Wall Street Journal'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines['publisher'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9353117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_source_tag(headline):\n",
    "    \"\"\"\n",
    "    after each headline, there is a \" - [source name]\" like \" - New York Times\". \n",
    "    \n",
    "    this function removes the final occurence of \" - ...\"\n",
    "    it doesn't perfectly remove the source tags, ie \" - WSJ - The Wall Street Journal\" becomes \"WSJ\"\n",
    "    \n",
    "    headline: string\n",
    "    \"\"\"\n",
    "    \n",
    "    split_title = headline.split(' - ')\n",
    "    n_splits = len(split_title) - 1\n",
    "    \n",
    "    return(' '.join(split_title[0:n_splits]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67cf02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_headlines(df, start_date='2018-01-01', end_date='2023-07-01'):\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['date'] = df['date'].apply(lambda ts: ts.replace(hour=0, minute=0, second=0))\n",
    "\n",
    "    # date range\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    \n",
    "    df = df.loc[(df['date'] >= start) & (df['date'] <= end)]\n",
    "    \n",
    "    # contains company names\n",
    "    df = df.loc[pd.Series(\n",
    "        df['title']\n",
    "    ).str.contains(\"|\".join(['Apple', 'Amazon', 'Google', \n",
    "                             'Microsoft','Nvidia']), case = False)]\n",
    "    \n",
    "    # remove duplicates\n",
    "    df.drop_duplicates()\n",
    "    \n",
    "    df['title'] = df['title'].apply(lambda headline : remove_source_tag(headline))\n",
    "    \n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4728cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = clean_headlines(headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820b73ba",
   "metadata": {},
   "source": [
    "### Add scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4102dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment_scores(df):\n",
    "    \n",
    "    compound = []\n",
    "    neg = []\n",
    "    neu = []\n",
    "    pos = []\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for headline in df['title']:\n",
    "        ss = sid.polarity_scores(headline)\n",
    "\n",
    "        compound.append(ss['compound'])\n",
    "        neg.append(ss['neg'])\n",
    "        neu.append(ss['neu'])\n",
    "        pos.append(ss['pos'])\n",
    "        \n",
    "    df['compound'] = compound\n",
    "    df['neg'] = neg\n",
    "    df['neu'] = neu\n",
    "    df['pos'] = pos\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a9c8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle_day(df):\n",
    "    \n",
    "    \n",
    "    # number of headlines per day\n",
    "    volume = df.groupby(['date', 'ticker']).count().iloc[:, 1]\n",
    "    \n",
    "    # take avg\n",
    "    df = df.groupby(['date', 'ticker']).mean(numeric_only = True)\n",
    "    df['volume'] = volume\n",
    "    \n",
    "    return df.reset_index().sort_values('date')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce22ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = add_sentiment_scores(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70cdd096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3 tips to maximize Apple's free Pages word pro...</td>\n",
       "      <td>TechRepublic</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>How to Switch Apple Watch Home Screen from Gri...</td>\n",
       "      <td>Wccftech</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Will Ferrell, Molly Shannon Tease Trump and Ti...</td>\n",
       "      <td>Hollywood Reporter</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>The Limits of Amazon WSJ</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon Mistakenly Sends AWS Budget Emails Fore...</td>\n",
       "      <td>BleepingComputer</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56959</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>New Apple Watch Ultra, 30-inch iMac make us sa...</td>\n",
       "      <td>Cult of Mac</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56960</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>A quick look back at Microsoft Bob, which was ...</td>\n",
       "      <td>Neowin</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56961</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>The Best Apple AirPods Models to Buy in 2023</td>\n",
       "      <td>IGN</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56962</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>How Google Beat Apple To AR And Still Failed</td>\n",
       "      <td>SlashGear</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56963</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>Nvidia Dlss 3 Plug-In Available Now For Unreal...</td>\n",
       "      <td>MENAFN.COM</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56964 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date ticker                                              title  \\\n",
       "0     2018-01-01   AAPL  3 tips to maximize Apple's free Pages word pro...   \n",
       "1     2018-01-01   AAPL  How to Switch Apple Watch Home Screen from Gri...   \n",
       "2     2018-01-01   AMZN  Will Ferrell, Molly Shannon Tease Trump and Ti...   \n",
       "3     2018-01-01   AMZN                           The Limits of Amazon WSJ   \n",
       "4     2018-01-01   AMZN  Amazon Mistakenly Sends AWS Budget Emails Fore...   \n",
       "...          ...    ...                                                ...   \n",
       "56959 2023-07-01   AAPL  New Apple Watch Ultra, 30-inch iMac make us sa...   \n",
       "56960 2023-07-01   MSFT  A quick look back at Microsoft Bob, which was ...   \n",
       "56961 2023-07-01   AAPL       The Best Apple AirPods Models to Buy in 2023   \n",
       "56962 2023-07-01   AAPL       How Google Beat Apple To AR And Still Failed   \n",
       "56963 2023-07-01   NVDA  Nvidia Dlss 3 Plug-In Available Now For Unreal...   \n",
       "\n",
       "                     publisher  compound    neg    neu    pos  \n",
       "0                 TechRepublic    0.5106  0.000  0.708  0.292  \n",
       "1                     Wccftech    0.0000  0.000  1.000  0.000  \n",
       "2           Hollywood Reporter   -0.3182  0.141  0.859  0.000  \n",
       "3      The Wall Street Journal    0.1779  0.000  0.702  0.298  \n",
       "4             BleepingComputer    0.4215  0.167  0.455  0.379  \n",
       "...                        ...       ...    ...    ...    ...  \n",
       "56959              Cult of Mac    0.0000  0.000  1.000  0.000  \n",
       "56960                   Neowin   -0.6249  0.215  0.785  0.000  \n",
       "56961                      IGN    0.6369  0.000  0.656  0.344  \n",
       "56962                SlashGear   -0.5106  0.292  0.708  0.000  \n",
       "56963               MENAFN.COM    0.0000  0.000  1.000  0.000  \n",
       "\n",
       "[56964 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "384c82a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.169250</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.594500</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.064093</td>\n",
       "      <td>0.093143</td>\n",
       "      <td>0.815571</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9263</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>-0.061820</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.888800</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9264</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>-0.129689</td>\n",
       "      <td>0.067333</td>\n",
       "      <td>0.932667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9261</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.112262</td>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.897308</td>\n",
       "      <td>0.080231</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9262</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.253340</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.700600</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9265</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>0.158071</td>\n",
       "      <td>0.031571</td>\n",
       "      <td>0.860429</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9266 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date ticker  compound       neg       neu       pos  volume\n",
       "0    2018-01-01   AAPL  0.255300  0.000000  0.854000  0.146000       2\n",
       "1    2018-01-01   AMZN  0.070300  0.077000  0.754000  0.169250       4\n",
       "2    2018-01-01   GOOG  0.249680  0.000000  0.843000  0.157000       5\n",
       "3    2018-01-01   MSFT  0.484700  0.081500  0.594500  0.324000       2\n",
       "4    2018-01-02   AAPL  0.064093  0.093143  0.815571  0.091286      14\n",
       "...         ...    ...       ...       ...       ...       ...     ...\n",
       "9263 2023-07-01   GOOG -0.061820  0.071200  0.888800  0.040000       5\n",
       "9264 2023-07-01   MSFT -0.129689  0.067333  0.932667  0.000000       9\n",
       "9261 2023-07-01   AAPL  0.112262  0.022462  0.897308  0.080231      13\n",
       "9262 2023-07-01   AMZN  0.253340  0.040400  0.700600  0.258900      10\n",
       "9265 2023-07-01   NVDA  0.158071  0.031571  0.860429  0.108000       7\n",
       "\n",
       "[9266 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_headlines = wrangle_day(headlines)\n",
    "day_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48bbac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_headlines.to_csv('daily_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b73fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
