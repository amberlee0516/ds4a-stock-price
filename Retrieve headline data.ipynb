{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8298734",
   "metadata": {},
   "source": [
    "# Retrieving headlines\n",
    "\n",
    "### Set up\n",
    "\n",
    "You may need to install the libraries `beautifulsoup4` and `newspaper3k`.\n",
    "\n",
    "The `GNews` library needs to be installed  from the Github source. Here is a [StackOverflow forum] I referenced, in case it is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install beautifulsoup4\n",
    "!{sys.executable} -m pip install newspaper3k\n",
    "!{sys.executable} -m pip install git+https://github.com/ranahaani/GNews.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd78bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gnews import GNews\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1868ae19",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87418aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the 2 week periods\n",
    "\n",
    "first_day = np.ones(12, dtype = int)\n",
    "middle_day = np.repeat(15, 12)\n",
    "middle_day[1] = 14 # feb\n",
    "last_day = np.tile([31, 30], 6)\n",
    "last_day[7:12] = last_day[0:5]\n",
    "last_day[1] = 28 # feb\n",
    "\n",
    "start_days = []\n",
    "end_days = []\n",
    "\n",
    "for i in range(12):\n",
    "    \n",
    "    start_days.append(first_day[i])\n",
    "    end_days.append(middle_day[i])\n",
    "    \n",
    "    start_days.append(middle_day[i])\n",
    "    end_days.append(last_day[i])\n",
    "\n",
    "months = np.repeat(range(12), 2) + 1\n",
    "\n",
    "# print(start_days)\n",
    "# print(end_days)\n",
    "# print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headlines(year, keyword):\n",
    "    \"\"\"\n",
    "    year: int \n",
    "    keyword: str, the company name\n",
    "    \"\"\"\n",
    "    \n",
    "    headlines_df = pd.DataFrame(columns = [\"date\", \"title\", \"publisher\"])\n",
    "    \n",
    "    for two_week_period in range(24):\n",
    "    \n",
    "        month = months[two_week_period]\n",
    "        start_day = start_days[two_week_period]\n",
    "        end_day = end_days[two_week_period]\n",
    "\n",
    "        start = dt.datetime(year, month, start_day)\n",
    "        end = dt.datetime(year, month, end_day)\n",
    "\n",
    "        gnews = GNews(language = \"en\",\n",
    "                      start_date = start, \n",
    "                      end_date = end)\n",
    "\n",
    "        news_df = pd.DataFrame(gnews.get_news(keyword))\n",
    "\n",
    "        if news_df.shape == (0, 0):\n",
    "            print(f\"No news between {start} and {end} for {keyword}.\\n\")\n",
    "            continue\n",
    "\n",
    "        news_df['date'] = pd.to_datetime(news_df['published date'])\n",
    "\n",
    "        headlines_df = pd.concat([headlines_df, news_df[['date', 'title', 'publisher']].copy()],\n",
    "                                 ignore_index = True)\n",
    "    \n",
    "    return headlines_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042c345",
   "metadata": {},
   "source": [
    "### Retrieve data\n",
    "\n",
    "Only run one cell at a time!\n",
    "\n",
    "When running these cells, you will get errors about having no news for certain time periods. That's fine, don't re-run the cell. Keep it the way it is so we have records about when the headlines were missing. Just commit and push what you have from that one run.\n",
    "\n",
    "One day later, it can be helpful to duplicate the cell, change the `range(2018, 2023+1)` to start from whichever year there is missing headlines, and run the code again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wafer: apple, amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591206eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apple\n",
    "\n",
    "company = \"Apple\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3559c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amazon\n",
    "\n",
    "company = \"Amazon\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cindy: nvidia, microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nvidia\n",
    "\n",
    "company = \"Nvidia\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c690786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# microsoft\n",
    "\n",
    "company = \"Microsoft\"\n",
    "\n",
    "for year in range(2018, 2023+1):\n",
    "\n",
    "    headlines_df = get_headlines(year, company)\n",
    "\n",
    "    file = \"headlines/\" + str(year) + \"_\" + company + \"_headlines.csv\"\n",
    "    headlines_df.to_csv(file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
